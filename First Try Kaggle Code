# %% [markdown]
# # Task for Today  
# 
# ***
# 
# ## EEG Emotion Prediction  
# 
# Given *EEG data from subjects who were watching movies*, let's try to predict the **emotional state** of a subject during a given movie.  
#   
# We will use a TensorFlow recurrent neural network to make our predictions.

# %% [markdown]
# # Getting Started

# %% [code] {"execution":{"iopub.status.busy":"2025-03-08T20:42:00.442766Z","iopub.execute_input":"2025-03-08T20:42:00.443040Z","iopub.status.idle":"2025-03-08T20:42:05.814601Z","shell.execute_reply.started":"2025-03-08T20:42:00.443015Z","shell.execute_reply":"2025-03-08T20:42:05.813904Z"}}
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split

import tensorflow as tf

from sklearn.metrics import confusion_matrix, classification_report

# %% [code] {"execution":{"iopub.status.busy":"2025-03-08T20:42:05.816460Z","iopub.execute_input":"2025-03-08T20:42:05.816692Z","iopub.status.idle":"2025-03-08T20:42:07.312258Z","shell.execute_reply.started":"2025-03-08T20:42:05.816670Z","shell.execute_reply":"2025-03-08T20:42:07.311575Z"}}
data = pd.read_csv('../input/eeg-brainwave-dataset-feeling-emotions/emotions.csv')

# %% [code] {"execution":{"iopub.status.busy":"2025-03-08T21:46:12.480501Z","iopub.execute_input":"2025-03-08T21:46:12.480873Z","iopub.status.idle":"2025-03-08T21:46:13.524769Z","shell.execute_reply.started":"2025-03-08T21:46:12.480838Z","shell.execute_reply":"2025-03-08T21:46:13.523959Z"}}
!python --version

# %% [code] {"execution":{"iopub.status.busy":"2025-03-08T21:46:54.500791Z","iopub.execute_input":"2025-03-08T21:46:54.501133Z","iopub.status.idle":"2025-03-08T21:46:54.506323Z","shell.execute_reply.started":"2025-03-08T21:46:54.501102Z","shell.execute_reply":"2025-03-08T21:46:54.505586Z"}}
tf.__version__

# %% [code] {"execution":{"iopub.status.busy":"2025-03-08T20:42:07.314098Z","iopub.execute_input":"2025-03-08T20:42:07.314340Z","iopub.status.idle":"2025-03-08T20:42:07.350832Z","shell.execute_reply.started":"2025-03-08T20:42:07.314317Z","shell.execute_reply":"2025-03-08T20:42:07.350093Z"}}
data

# %% [code] {"execution":{"iopub.status.busy":"2025-03-08T20:42:07.352098Z","iopub.execute_input":"2025-03-08T20:42:07.352336Z","iopub.status.idle":"2025-03-08T20:42:07.599136Z","shell.execute_reply.started":"2025-03-08T20:42:07.352312Z","shell.execute_reply":"2025-03-08T20:42:07.598375Z"}}
sample = data.loc[0, 'fft_0_b':'fft_749_b']

plt.figure(figsize=(16, 10))
plt.plot(range(len(sample)), sample)
plt.title("Features fft_0_b through fft_749_b")
plt.show()

# %% [code] {"execution":{"iopub.status.busy":"2025-03-08T20:42:07.600639Z","iopub.execute_input":"2025-03-08T20:42:07.601002Z","iopub.status.idle":"2025-03-08T20:42:07.609164Z","shell.execute_reply.started":"2025-03-08T20:42:07.600966Z","shell.execute_reply":"2025-03-08T20:42:07.608337Z"}}
data['label'].value_counts()

# %% [code] {"execution":{"iopub.status.busy":"2025-03-08T20:42:07.610435Z","iopub.execute_input":"2025-03-08T20:42:07.610778Z","iopub.status.idle":"2025-03-08T20:42:07.619954Z","shell.execute_reply.started":"2025-03-08T20:42:07.610733Z","shell.execute_reply":"2025-03-08T20:42:07.619240Z"}}
label_mapping = {'NEGATIVE': 0, 'NEUTRAL': 1, 'POSITIVE': 2}

# %% [markdown]
# # Preprocessing

# %% [code] {"execution":{"iopub.status.busy":"2025-03-08T20:42:07.620764Z","iopub.execute_input":"2025-03-08T20:42:07.621063Z","iopub.status.idle":"2025-03-08T20:42:07.628517Z","shell.execute_reply.started":"2025-03-08T20:42:07.621039Z","shell.execute_reply":"2025-03-08T20:42:07.627787Z"}}
def preprocess_inputs(df):
    df = df.copy()
    
    df['label'] = df['label'].replace(label_mapping)
    
    y = df['label'].copy()
    X = df.drop('label', axis=1).copy()
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)
    
    return X_train, X_test, y_train, y_test

# %% [code] {"execution":{"iopub.status.busy":"2025-03-08T20:42:07.629477Z","iopub.execute_input":"2025-03-08T20:42:07.629732Z","iopub.status.idle":"2025-03-08T20:42:07.712322Z","shell.execute_reply.started":"2025-03-08T20:42:07.629709Z","shell.execute_reply":"2025-03-08T20:42:07.711672Z"}}
X_train, X_test, y_train, y_test = preprocess_inputs(data)

# %% [code] {"execution":{"iopub.status.busy":"2025-03-08T20:42:07.713304Z","iopub.execute_input":"2025-03-08T20:42:07.713521Z","iopub.status.idle":"2025-03-08T20:42:07.740518Z","shell.execute_reply.started":"2025-03-08T20:42:07.713499Z","shell.execute_reply":"2025-03-08T20:42:07.739904Z"}}
X_train

# %% [markdown]
# # Modeling

# %% [code] {"execution":{"iopub.status.busy":"2025-03-08T20:42:07.741526Z","iopub.execute_input":"2025-03-08T20:42:07.741727Z","iopub.status.idle":"2025-03-08T20:42:10.179561Z","shell.execute_reply.started":"2025-03-08T20:42:07.741707Z","shell.execute_reply":"2025-03-08T20:42:10.178767Z"}}
inputs = tf.keras.Input(shape=(X_train.shape[1],))

expand_dims = tf.expand_dims(inputs, axis=2)

gru = tf.keras.layers.GRU(256, return_sequences=True)(expand_dims)

flatten = tf.keras.layers.Flatten()(gru)

outputs = tf.keras.layers.Dense(3, activation='softmax')(flatten)


model = tf.keras.Model(inputs=inputs, outputs=outputs)
print(model.summary())

# %% [code] {"execution":{"iopub.status.busy":"2025-03-08T20:42:10.180604Z","iopub.execute_input":"2025-03-08T20:42:10.180847Z","iopub.status.idle":"2025-03-08T20:43:47.209595Z","shell.execute_reply.started":"2025-03-08T20:42:10.180793Z","shell.execute_reply":"2025-03-08T20:43:47.208828Z"}}
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

history = model.fit(
    X_train,
    y_train,
    validation_split=0.2,
    batch_size=32,
    epochs=50,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=5,
            restore_best_weights=True
        )
    ]
)

# %% [markdown]
# # Results

# %% [code] {"execution":{"iopub.status.busy":"2025-03-08T20:43:47.210803Z","iopub.execute_input":"2025-03-08T20:43:47.211174Z","iopub.status.idle":"2025-03-08T20:43:48.632506Z","shell.execute_reply.started":"2025-03-08T20:43:47.211139Z","shell.execute_reply":"2025-03-08T20:43:48.631762Z"}}
model_acc = model.evaluate(X_test, y_test, verbose=0)[1]
print("Test Accuracy: {:.3f}%".format(model_acc * 100))

# %% [code] {"execution":{"iopub.status.busy":"2025-03-08T20:43:48.633577Z","iopub.execute_input":"2025-03-08T20:43:48.633869Z","iopub.status.idle":"2025-03-08T20:43:50.298395Z","shell.execute_reply.started":"2025-03-08T20:43:48.633802Z","shell.execute_reply":"2025-03-08T20:43:50.297520Z"}}
y_pred = np.array(list(map(lambda x: np.argmax(x), model.predict(X_test))))

cm = confusion_matrix(y_test, y_pred)
clr = classification_report(y_test, y_pred, target_names=label_mapping.keys())

plt.figure(figsize=(8, 8))
sns.heatmap(cm, annot=True, vmin=0, fmt='g', cbar=False, cmap='Blues')
plt.xticks(np.arange(3) + 0.5, label_mapping.keys())
plt.yticks(np.arange(3) + 0.5, label_mapping.keys())
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

print("Classification Report:\n----------------------\n", clr)

# %% [code] {"execution":{"iopub.status.busy":"2025-03-08T20:47:42.253441Z","iopub.execute_input":"2025-03-08T20:47:42.253786Z","iopub.status.idle":"2025-03-08T20:47:42.330770Z","shell.execute_reply.started":"2025-03-08T20:47:42.253754Z","shell.execute_reply":"2025-03-08T20:47:42.329864Z"}}
model.save("/kaggle/working/model.h5")

# %% [code] {"execution":{"iopub.status.busy":"2025-03-08T20:46:33.109330Z","iopub.execute_input":"2025-03-08T20:46:33.109648Z","iopub.status.idle":"2025-03-08T20:46:35.406704Z","shell.execute_reply.started":"2025-03-08T20:46:33.109624Z","shell.execute_reply":"2025-03-08T20:46:35.405738Z"}}
!zip -r model.zip /kaggle/working/model.h5

# %% [markdown]
# # Data Every Day  
# 
# This notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  
# 
# ***
# 
# Check it out!  
# https://youtu.be/IAQdqaoHrfE
